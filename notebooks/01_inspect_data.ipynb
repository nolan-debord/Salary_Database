{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb7052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0671e08",
   "metadata": {},
   "source": [
    "### Load the data into dataframes, and check to ensure integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4688ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets into panda dataframes\n",
    "salary_df = pd.read_csv('../data/salary.csv')\n",
    "housing_df = pd.read_csv('../data/home_values.csv')\n",
    "col_df = pd.read_csv('../data/cost_of_living.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e7936ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA_TITLE</th>\n",
       "      <th>AREA_TYPE</th>\n",
       "      <th>PRIM_STATE</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NAICS_TITLE</th>\n",
       "      <th>I_GROUP</th>\n",
       "      <th>OWN_CODE</th>\n",
       "      <th>OCC_CODE</th>\n",
       "      <th>OCC_TITLE</th>\n",
       "      <th>...</th>\n",
       "      <th>H_MEDIAN</th>\n",
       "      <th>H_PCT75</th>\n",
       "      <th>H_PCT90</th>\n",
       "      <th>A_PCT10</th>\n",
       "      <th>A_PCT25</th>\n",
       "      <th>A_MEDIAN</th>\n",
       "      <th>A_PCT75</th>\n",
       "      <th>A_PCT90</th>\n",
       "      <th>ANNUAL</th>\n",
       "      <th>HOURLY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2</td>\n",
       "      <td>TN</td>\n",
       "      <td>0</td>\n",
       "      <td>Cross-industry</td>\n",
       "      <td>cross-industry</td>\n",
       "      <td>1235</td>\n",
       "      <td>15-2051</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>...</td>\n",
       "      <td>50.34</td>\n",
       "      <td>66.29</td>\n",
       "      <td>91.35</td>\n",
       "      <td>61,960</td>\n",
       "      <td>82,060</td>\n",
       "      <td>104,700</td>\n",
       "      <td>137,880</td>\n",
       "      <td>190,000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>Cross-industry</td>\n",
       "      <td>cross-industry</td>\n",
       "      <td>1235</td>\n",
       "      <td>15-2051</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>...</td>\n",
       "      <td>51.22</td>\n",
       "      <td>66.15</td>\n",
       "      <td>81.40</td>\n",
       "      <td>61,230</td>\n",
       "      <td>81,140</td>\n",
       "      <td>106,540</td>\n",
       "      <td>137,590</td>\n",
       "      <td>169,310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2</td>\n",
       "      <td>TN</td>\n",
       "      <td>0</td>\n",
       "      <td>Cross-industry</td>\n",
       "      <td>cross-industry</td>\n",
       "      <td>1235</td>\n",
       "      <td>29-1141</td>\n",
       "      <td>Registered Nurses</td>\n",
       "      <td>...</td>\n",
       "      <td>38.00</td>\n",
       "      <td>42.49</td>\n",
       "      <td>49.06</td>\n",
       "      <td>59,540</td>\n",
       "      <td>67,110</td>\n",
       "      <td>79,030</td>\n",
       "      <td>88,380</td>\n",
       "      <td>102,040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>Cross-industry</td>\n",
       "      <td>cross-industry</td>\n",
       "      <td>1235</td>\n",
       "      <td>29-1141</td>\n",
       "      <td>Registered Nurses</td>\n",
       "      <td>...</td>\n",
       "      <td>43.27</td>\n",
       "      <td>49.14</td>\n",
       "      <td>58.69</td>\n",
       "      <td>64,660</td>\n",
       "      <td>77,450</td>\n",
       "      <td>90,010</td>\n",
       "      <td>102,200</td>\n",
       "      <td>122,060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10180</td>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>4</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>Cross-industry</td>\n",
       "      <td>cross-industry</td>\n",
       "      <td>1235</td>\n",
       "      <td>15-2051</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>...</td>\n",
       "      <td>45.82</td>\n",
       "      <td>54.20</td>\n",
       "      <td>62.01</td>\n",
       "      <td>39,080</td>\n",
       "      <td>65,090</td>\n",
       "      <td>95,310</td>\n",
       "      <td>112,730</td>\n",
       "      <td>128,980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AREA   AREA_TITLE  AREA_TYPE PRIM_STATE  NAICS     NAICS_TITLE  \\\n",
       "0     47    Tennessee          2         TN      0  Cross-industry   \n",
       "1     48        Texas          2         TX      0  Cross-industry   \n",
       "2     47    Tennessee          2         TN      0  Cross-industry   \n",
       "3     48        Texas          2         TX      0  Cross-industry   \n",
       "4  10180  Abilene, TX          4         TX      0  Cross-industry   \n",
       "\n",
       "          I_GROUP  OWN_CODE OCC_CODE          OCC_TITLE  ... H_MEDIAN H_PCT75  \\\n",
       "0  cross-industry      1235  15-2051    Data Scientists  ...    50.34   66.29   \n",
       "1  cross-industry      1235  15-2051    Data Scientists  ...    51.22   66.15   \n",
       "2  cross-industry      1235  29-1141  Registered Nurses  ...    38.00   42.49   \n",
       "3  cross-industry      1235  29-1141  Registered Nurses  ...    43.27   49.14   \n",
       "4  cross-industry      1235  15-2051    Data Scientists  ...    45.82   54.20   \n",
       "\n",
       "   H_PCT90  A_PCT10  A_PCT25  A_MEDIAN  A_PCT75  A_PCT90 ANNUAL  HOURLY  \n",
       "0    91.35   61,960   82,060   104,700  137,880  190,000    NaN     NaN  \n",
       "1    81.40   61,230   81,140   106,540  137,590  169,310    NaN     NaN  \n",
       "2    49.06   59,540   67,110    79,030   88,380  102,040    NaN     NaN  \n",
       "3    58.69   64,660   77,450    90,010  102,200  122,060    NaN     NaN  \n",
       "4    62.01   39,080   65,090    95,310  112,730  128,980    NaN     NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db463ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>1/31/2000</th>\n",
       "      <th>2/29/2000</th>\n",
       "      <th>3/31/2000</th>\n",
       "      <th>4/30/2000</th>\n",
       "      <th>5/31/2000</th>\n",
       "      <th>...</th>\n",
       "      <th>8/31/2024</th>\n",
       "      <th>9/30/2024</th>\n",
       "      <th>10/31/2024</th>\n",
       "      <th>11/30/2024</th>\n",
       "      <th>12/31/2024</th>\n",
       "      <th>1/31/2025</th>\n",
       "      <th>2/28/2025</th>\n",
       "      <th>3/31/2025</th>\n",
       "      <th>4/30/2025</th>\n",
       "      <th>5/31/2025</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102001</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>country</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124341.4562</td>\n",
       "      <td>124560.2127</td>\n",
       "      <td>124831.5029</td>\n",
       "      <td>125413.3673</td>\n",
       "      <td>126083.0233</td>\n",
       "      <td>...</td>\n",
       "      <td>366082.5346</td>\n",
       "      <td>366541.0340</td>\n",
       "      <td>367139.8895</td>\n",
       "      <td>367641.5758</td>\n",
       "      <td>368374.1942</td>\n",
       "      <td>369014.8924</td>\n",
       "      <td>369482.2883</td>\n",
       "      <td>369202.3862</td>\n",
       "      <td>368665.5743</td>\n",
       "      <td>367968.7057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394913</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>222144.7324</td>\n",
       "      <td>223088.7221</td>\n",
       "      <td>224041.4550</td>\n",
       "      <td>225972.0603</td>\n",
       "      <td>227971.2690</td>\n",
       "      <td>...</td>\n",
       "      <td>684259.3824</td>\n",
       "      <td>688392.1380</td>\n",
       "      <td>692009.2026</td>\n",
       "      <td>694852.7965</td>\n",
       "      <td>696684.0190</td>\n",
       "      <td>697783.9714</td>\n",
       "      <td>699099.8650</td>\n",
       "      <td>700827.9523</td>\n",
       "      <td>703306.7753</td>\n",
       "      <td>705107.6255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>227474.6703</td>\n",
       "      <td>228321.1647</td>\n",
       "      <td>229448.6871</td>\n",
       "      <td>231692.0781</td>\n",
       "      <td>234145.6444</td>\n",
       "      <td>...</td>\n",
       "      <td>968498.3033</td>\n",
       "      <td>975119.7774</td>\n",
       "      <td>980502.5479</td>\n",
       "      <td>985140.3668</td>\n",
       "      <td>989285.8683</td>\n",
       "      <td>989838.1139</td>\n",
       "      <td>987754.6575</td>\n",
       "      <td>982522.4865</td>\n",
       "      <td>978090.5113</td>\n",
       "      <td>973190.3033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394463</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>msa</td>\n",
       "      <td>IL</td>\n",
       "      <td>157959.1465</td>\n",
       "      <td>158105.3707</td>\n",
       "      <td>158383.8571</td>\n",
       "      <td>159076.6623</td>\n",
       "      <td>159910.0236</td>\n",
       "      <td>...</td>\n",
       "      <td>332736.3341</td>\n",
       "      <td>333770.6434</td>\n",
       "      <td>334778.5778</td>\n",
       "      <td>335849.1447</td>\n",
       "      <td>337135.0235</td>\n",
       "      <td>338519.7976</td>\n",
       "      <td>339906.1230</td>\n",
       "      <td>340776.9626</td>\n",
       "      <td>341395.6137</td>\n",
       "      <td>341694.7701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394514</td>\n",
       "      <td>4</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>130592.6920</td>\n",
       "      <td>130650.8585</td>\n",
       "      <td>130717.7267</td>\n",
       "      <td>130891.3766</td>\n",
       "      <td>131120.3293</td>\n",
       "      <td>...</td>\n",
       "      <td>385874.0269</td>\n",
       "      <td>385669.1886</td>\n",
       "      <td>385559.5613</td>\n",
       "      <td>385261.0522</td>\n",
       "      <td>384718.5649</td>\n",
       "      <td>384177.3123</td>\n",
       "      <td>383371.6226</td>\n",
       "      <td>381834.2156</td>\n",
       "      <td>379657.8131</td>\n",
       "      <td>377185.6705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  SizeRank       RegionName RegionType StateName    1/31/2000  \\\n",
       "0    102001         0    United States    country       NaN  124341.4562   \n",
       "1    394913         1     New York, NY        msa        NY  222144.7324   \n",
       "2    753899         2  Los Angeles, CA        msa        CA  227474.6703   \n",
       "3    394463         3      Chicago, IL        msa        IL  157959.1465   \n",
       "4    394514         4       Dallas, TX        msa        TX  130592.6920   \n",
       "\n",
       "     2/29/2000    3/31/2000    4/30/2000    5/31/2000  ...    8/31/2024  \\\n",
       "0  124560.2127  124831.5029  125413.3673  126083.0233  ...  366082.5346   \n",
       "1  223088.7221  224041.4550  225972.0603  227971.2690  ...  684259.3824   \n",
       "2  228321.1647  229448.6871  231692.0781  234145.6444  ...  968498.3033   \n",
       "3  158105.3707  158383.8571  159076.6623  159910.0236  ...  332736.3341   \n",
       "4  130650.8585  130717.7267  130891.3766  131120.3293  ...  385874.0269   \n",
       "\n",
       "     9/30/2024   10/31/2024   11/30/2024   12/31/2024    1/31/2025  \\\n",
       "0  366541.0340  367139.8895  367641.5758  368374.1942  369014.8924   \n",
       "1  688392.1380  692009.2026  694852.7965  696684.0190  697783.9714   \n",
       "2  975119.7774  980502.5479  985140.3668  989285.8683  989838.1139   \n",
       "3  333770.6434  334778.5778  335849.1447  337135.0235  338519.7976   \n",
       "4  385669.1886  385559.5613  385261.0522  384718.5649  384177.3123   \n",
       "\n",
       "     2/28/2025    3/31/2025    4/30/2025    5/31/2025  \n",
       "0  369482.2883  369202.3862  368665.5743  367968.7057  \n",
       "1  699099.8650  700827.9523  703306.7753  705107.6255  \n",
       "2  987754.6575  982522.4865  978090.5113  973190.3033  \n",
       "3  339906.1230  340776.9626  341395.6137  341694.7701  \n",
       "4  383371.6226  381834.2156  379657.8131  377185.6705  \n",
       "\n",
       "[5 rows x 310 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3463aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>City</th>\n",
       "      <th>Cost of Living Index</th>\n",
       "      <th>Rent Index</th>\n",
       "      <th>Cost of Living Plus Rent Index</th>\n",
       "      <th>Groceries Index</th>\n",
       "      <th>Restaurant Price Index</th>\n",
       "      <th>Local Purchasing Power Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Honolulu, HI</td>\n",
       "      <td>94.6</td>\n",
       "      <td>57.8</td>\n",
       "      <td>78.5</td>\n",
       "      <td>120.2</td>\n",
       "      <td>84.7</td>\n",
       "      <td>106.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>90.3</td>\n",
       "      <td>78.5</td>\n",
       "      <td>85.1</td>\n",
       "      <td>99.4</td>\n",
       "      <td>91.3</td>\n",
       "      <td>168.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>85.5</td>\n",
       "      <td>60.8</td>\n",
       "      <td>74.7</td>\n",
       "      <td>94.2</td>\n",
       "      <td>87.2</td>\n",
       "      <td>171.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>84.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>89.8</td>\n",
       "      <td>77.7</td>\n",
       "      <td>139.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank               City  Cost of Living Index  Rent Index  \\\n",
       "0     1       New York, NY                 100.0       100.0   \n",
       "1     2       Honolulu, HI                  94.6        57.8   \n",
       "2     3  San Francisco, CA                  90.3        78.5   \n",
       "3     4        Seattle, WA                  85.5        60.8   \n",
       "4     5       San Jose, CA                  84.0        76.0   \n",
       "\n",
       "   Cost of Living Plus Rent Index  Groceries Index  Restaurant Price Index  \\\n",
       "0                           100.0            100.0                   100.0   \n",
       "1                            78.5            120.2                    84.7   \n",
       "2                            85.1             99.4                    91.3   \n",
       "3                            74.7             94.2                    87.2   \n",
       "4                            80.5             89.8                    77.7   \n",
       "\n",
       "   Local Purchasing Power Index  \n",
       "0                         100.0  \n",
       "1                         106.3  \n",
       "2                         168.6  \n",
       "3                         171.5  \n",
       "4                         139.7  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365092a1",
   "metadata": {},
   "source": [
    "#### Merge the dataframes into one singular dataset to be used for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d42a2afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AREA',\n",
       " 'AREA_TITLE',\n",
       " 'AREA_TYPE',\n",
       " 'PRIM_STATE',\n",
       " 'NAICS',\n",
       " 'NAICS_TITLE',\n",
       " 'I_GROUP',\n",
       " 'OWN_CODE',\n",
       " 'OCC_CODE',\n",
       " 'OCC_TITLE',\n",
       " 'O_GROUP',\n",
       " 'TOT_EMP',\n",
       " 'EMP_PRSE',\n",
       " 'JOBS_1000',\n",
       " 'LOC_QUOTIENT',\n",
       " 'PCT_TOTAL',\n",
       " 'PCT_RPT',\n",
       " 'H_MEAN',\n",
       " 'A_MEAN',\n",
       " 'MEAN_PRSE',\n",
       " 'H_PCT10',\n",
       " 'H_PCT25',\n",
       " 'H_MEDIAN',\n",
       " 'H_PCT75',\n",
       " 'H_PCT90',\n",
       " 'A_PCT10',\n",
       " 'A_PCT25',\n",
       " 'A_MEDIAN',\n",
       " 'A_PCT75',\n",
       " 'A_PCT90',\n",
       " 'ANNUAL',\n",
       " 'HOURLY']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a712872d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RegionID',\n",
       " 'SizeRank',\n",
       " 'RegionName',\n",
       " 'RegionType',\n",
       " 'StateName',\n",
       " '1/31/2000',\n",
       " '2/29/2000',\n",
       " '3/31/2000',\n",
       " '4/30/2000',\n",
       " '5/31/2000',\n",
       " '6/30/2000',\n",
       " '7/31/2000',\n",
       " '8/31/2000',\n",
       " '9/30/2000',\n",
       " '10/31/2000',\n",
       " '11/30/2000',\n",
       " '12/31/2000',\n",
       " '1/31/2001',\n",
       " '2/28/2001',\n",
       " '3/31/2001',\n",
       " '4/30/2001',\n",
       " '5/31/2001',\n",
       " '6/30/2001',\n",
       " '7/31/2001',\n",
       " '8/31/2001',\n",
       " '9/30/2001',\n",
       " '10/31/2001',\n",
       " '11/30/2001',\n",
       " '12/31/2001',\n",
       " '1/31/2002',\n",
       " '2/28/2002',\n",
       " '3/31/2002',\n",
       " '4/30/2002',\n",
       " '5/31/2002',\n",
       " '6/30/2002',\n",
       " '7/31/2002',\n",
       " '8/31/2002',\n",
       " '9/30/2002',\n",
       " '10/31/2002',\n",
       " '11/30/2002',\n",
       " '12/31/2002',\n",
       " '1/31/2003',\n",
       " '2/28/2003',\n",
       " '3/31/2003',\n",
       " '4/30/2003',\n",
       " '5/31/2003',\n",
       " '6/30/2003',\n",
       " '7/31/2003',\n",
       " '8/31/2003',\n",
       " '9/30/2003',\n",
       " '10/31/2003',\n",
       " '11/30/2003',\n",
       " '12/31/2003',\n",
       " '1/31/2004',\n",
       " '2/29/2004',\n",
       " '3/31/2004',\n",
       " '4/30/2004',\n",
       " '5/31/2004',\n",
       " '6/30/2004',\n",
       " '7/31/2004',\n",
       " '8/31/2004',\n",
       " '9/30/2004',\n",
       " '10/31/2004',\n",
       " '11/30/2004',\n",
       " '12/31/2004',\n",
       " '1/31/2005',\n",
       " '2/28/2005',\n",
       " '3/31/2005',\n",
       " '4/30/2005',\n",
       " '5/31/2005',\n",
       " '6/30/2005',\n",
       " '7/31/2005',\n",
       " '8/31/2005',\n",
       " '9/30/2005',\n",
       " '10/31/2005',\n",
       " '11/30/2005',\n",
       " '12/31/2005',\n",
       " '1/31/2006',\n",
       " '2/28/2006',\n",
       " '3/31/2006',\n",
       " '4/30/2006',\n",
       " '5/31/2006',\n",
       " '6/30/2006',\n",
       " '7/31/2006',\n",
       " '8/31/2006',\n",
       " '9/30/2006',\n",
       " '10/31/2006',\n",
       " '11/30/2006',\n",
       " '12/31/2006',\n",
       " '1/31/2007',\n",
       " '2/28/2007',\n",
       " '3/31/2007',\n",
       " '4/30/2007',\n",
       " '5/31/2007',\n",
       " '6/30/2007',\n",
       " '7/31/2007',\n",
       " '8/31/2007',\n",
       " '9/30/2007',\n",
       " '10/31/2007',\n",
       " '11/30/2007',\n",
       " '12/31/2007',\n",
       " '1/31/2008',\n",
       " '2/29/2008',\n",
       " '3/31/2008',\n",
       " '4/30/2008',\n",
       " '5/31/2008',\n",
       " '6/30/2008',\n",
       " '7/31/2008',\n",
       " '8/31/2008',\n",
       " '9/30/2008',\n",
       " '10/31/2008',\n",
       " '11/30/2008',\n",
       " '12/31/2008',\n",
       " '1/31/2009',\n",
       " '2/28/2009',\n",
       " '3/31/2009',\n",
       " '4/30/2009',\n",
       " '5/31/2009',\n",
       " '6/30/2009',\n",
       " '7/31/2009',\n",
       " '8/31/2009',\n",
       " '9/30/2009',\n",
       " '10/31/2009',\n",
       " '11/30/2009',\n",
       " '12/31/2009',\n",
       " '1/31/2010',\n",
       " '2/28/2010',\n",
       " '3/31/2010',\n",
       " '4/30/2010',\n",
       " '5/31/2010',\n",
       " '6/30/2010',\n",
       " '7/31/2010',\n",
       " '8/31/2010',\n",
       " '9/30/2010',\n",
       " '10/31/2010',\n",
       " '11/30/2010',\n",
       " '12/31/2010',\n",
       " '1/31/2011',\n",
       " '2/28/2011',\n",
       " '3/31/2011',\n",
       " '4/30/2011',\n",
       " '5/31/2011',\n",
       " '6/30/2011',\n",
       " '7/31/2011',\n",
       " '8/31/2011',\n",
       " '9/30/2011',\n",
       " '10/31/2011',\n",
       " '11/30/2011',\n",
       " '12/31/2011',\n",
       " '1/31/2012',\n",
       " '2/29/2012',\n",
       " '3/31/2012',\n",
       " '4/30/2012',\n",
       " '5/31/2012',\n",
       " '6/30/2012',\n",
       " '7/31/2012',\n",
       " '8/31/2012',\n",
       " '9/30/2012',\n",
       " '10/31/2012',\n",
       " '11/30/2012',\n",
       " '12/31/2012',\n",
       " '1/31/2013',\n",
       " '2/28/2013',\n",
       " '3/31/2013',\n",
       " '4/30/2013',\n",
       " '5/31/2013',\n",
       " '6/30/2013',\n",
       " '7/31/2013',\n",
       " '8/31/2013',\n",
       " '9/30/2013',\n",
       " '10/31/2013',\n",
       " '11/30/2013',\n",
       " '12/31/2013',\n",
       " '1/31/2014',\n",
       " '2/28/2014',\n",
       " '3/31/2014',\n",
       " '4/30/2014',\n",
       " '5/31/2014',\n",
       " '6/30/2014',\n",
       " '7/31/2014',\n",
       " '8/31/2014',\n",
       " '9/30/2014',\n",
       " '10/31/2014',\n",
       " '11/30/2014',\n",
       " '12/31/2014',\n",
       " '1/31/2015',\n",
       " '2/28/2015',\n",
       " '3/31/2015',\n",
       " '4/30/2015',\n",
       " '5/31/2015',\n",
       " '6/30/2015',\n",
       " '7/31/2015',\n",
       " '8/31/2015',\n",
       " '9/30/2015',\n",
       " '10/31/2015',\n",
       " '11/30/2015',\n",
       " '12/31/2015',\n",
       " '1/31/2016',\n",
       " '2/29/2016',\n",
       " '3/31/2016',\n",
       " '4/30/2016',\n",
       " '5/31/2016',\n",
       " '6/30/2016',\n",
       " '7/31/2016',\n",
       " '8/31/2016',\n",
       " '9/30/2016',\n",
       " '10/31/2016',\n",
       " '11/30/2016',\n",
       " '12/31/2016',\n",
       " '1/31/2017',\n",
       " '2/28/2017',\n",
       " '3/31/2017',\n",
       " '4/30/2017',\n",
       " '5/31/2017',\n",
       " '6/30/2017',\n",
       " '7/31/2017',\n",
       " '8/31/2017',\n",
       " '9/30/2017',\n",
       " '10/31/2017',\n",
       " '11/30/2017',\n",
       " '12/31/2017',\n",
       " '1/31/2018',\n",
       " '2/28/2018',\n",
       " '3/31/2018',\n",
       " '4/30/2018',\n",
       " '5/31/2018',\n",
       " '6/30/2018',\n",
       " '7/31/2018',\n",
       " '8/31/2018',\n",
       " '9/30/2018',\n",
       " '10/31/2018',\n",
       " '11/30/2018',\n",
       " '12/31/2018',\n",
       " '1/31/2019',\n",
       " '2/28/2019',\n",
       " '3/31/2019',\n",
       " '4/30/2019',\n",
       " '5/31/2019',\n",
       " '6/30/2019',\n",
       " '7/31/2019',\n",
       " '8/31/2019',\n",
       " '9/30/2019',\n",
       " '10/31/2019',\n",
       " '11/30/2019',\n",
       " '12/31/2019',\n",
       " '1/31/2020',\n",
       " '2/29/2020',\n",
       " '3/31/2020',\n",
       " '4/30/2020',\n",
       " '5/31/2020',\n",
       " '6/30/2020',\n",
       " '7/31/2020',\n",
       " '8/31/2020',\n",
       " '9/30/2020',\n",
       " '10/31/2020',\n",
       " '11/30/2020',\n",
       " '12/31/2020',\n",
       " '1/31/2021',\n",
       " '2/28/2021',\n",
       " '3/31/2021',\n",
       " '4/30/2021',\n",
       " '5/31/2021',\n",
       " '6/30/2021',\n",
       " '7/31/2021',\n",
       " '8/31/2021',\n",
       " '9/30/2021',\n",
       " '10/31/2021',\n",
       " '11/30/2021',\n",
       " '12/31/2021',\n",
       " '1/31/2022',\n",
       " '2/28/2022',\n",
       " '3/31/2022',\n",
       " '4/30/2022',\n",
       " '5/31/2022',\n",
       " '6/30/2022',\n",
       " '7/31/2022',\n",
       " '8/31/2022',\n",
       " '9/30/2022',\n",
       " '10/31/2022',\n",
       " '11/30/2022',\n",
       " '12/31/2022',\n",
       " '1/31/2023',\n",
       " '2/28/2023',\n",
       " '3/31/2023',\n",
       " '4/30/2023',\n",
       " '5/31/2023',\n",
       " '6/30/2023',\n",
       " '7/31/2023',\n",
       " '8/31/2023',\n",
       " '9/30/2023',\n",
       " '10/31/2023',\n",
       " '11/30/2023',\n",
       " '12/31/2023',\n",
       " '1/31/2024',\n",
       " '2/29/2024',\n",
       " '3/31/2024',\n",
       " '4/30/2024',\n",
       " '5/31/2024',\n",
       " '6/30/2024',\n",
       " '7/31/2024',\n",
       " '8/31/2024',\n",
       " '9/30/2024',\n",
       " '10/31/2024',\n",
       " '11/30/2024',\n",
       " '12/31/2024',\n",
       " '1/31/2025',\n",
       " '2/28/2025',\n",
       " '3/31/2025',\n",
       " '4/30/2025',\n",
       " '5/31/2025']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "baec4653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank',\n",
       " 'City',\n",
       " 'Cost of Living Index',\n",
       " 'Rent Index',\n",
       " 'Cost of Living Plus Rent Index',\n",
       " 'Groceries Index',\n",
       " 'Restaurant Price Index',\n",
       " 'Local Purchasing Power Index']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6ee4375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA_TITLE</th>\n",
       "      <th>PRIM_STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amarillo, TX</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Austin-Round Rock-San Marcos, TX</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beaumont-Port Arthur, TX</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chattanooga, TN-GA</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarksville, TN-KY</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>College Station-Bryan, TX</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Corpus Christi, TX</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          AREA_TITLE PRIM_STATE\n",
       "0                          Tennessee         TN\n",
       "1                              Texas         TX\n",
       "4                        Abilene, TX         TX\n",
       "5                       Amarillo, TX         TX\n",
       "6   Austin-Round Rock-San Marcos, TX         TX\n",
       "7           Beaumont-Port Arthur, TX         TX\n",
       "8                 Chattanooga, TN-GA         TN\n",
       "9                 Clarksville, TN-KY         TN\n",
       "10         College Station-Bryan, TX         TX\n",
       "11                Corpus Christi, TX         TX"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_df[['AREA_TITLE', 'PRIM_STATE']].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50451a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionName</th>\n",
       "      <th>StateName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Miami, FL</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RegionName StateName\n",
       "0     United States       NaN\n",
       "1      New York, NY        NY\n",
       "2   Los Angeles, CA        CA\n",
       "3       Chicago, IL        IL\n",
       "4        Dallas, TX        TX\n",
       "5       Houston, TX        TX\n",
       "6    Washington, DC        VA\n",
       "7  Philadelphia, PA        PA\n",
       "8         Miami, FL        FL\n",
       "9       Atlanta, GA        GA"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df[['RegionName', 'StateName']].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8289874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Honolulu, HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seattle, WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Jose, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Washington, DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston, MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>San Diego, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Miami, FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                City\n",
       "0       New York, NY\n",
       "1       Honolulu, HI\n",
       "2  San Francisco, CA\n",
       "3        Seattle, WA\n",
       "4       San Jose, CA\n",
       "5     Washington, DC\n",
       "6         Boston, MA\n",
       "7    Los Angeles, CA\n",
       "8      San Diego, CA\n",
       "9          Miami, FL"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_df[['City']].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e8a9e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abilene</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amarillo</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beaumont</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chattanooga</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarksville</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>College Station</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Corpus Christi</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City State\n",
       "4           Abilene    TX\n",
       "5          Amarillo    TX\n",
       "6            Austin    TX\n",
       "7          Beaumont    TX\n",
       "8       Chattanooga    TN\n",
       "9       Clarksville    TN\n",
       "10  College Station    TX\n",
       "11   Corpus Christi    TX\n",
       "12           Dallas    TX\n",
       "13          El Paso    TX"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the State level rows from the salary_df dataset\n",
    "# Will only keep rows where the AREA_TITLE contains a , like \"Houston, TX\"\n",
    "# Will eliminate \"USA\", \"TX\" and other single state/country references\n",
    "salary_df = salary_df[salary_df['AREA_TITLE'].str.contains(\",\")]\n",
    "\n",
    "# Seperate the city, state into two seperate columns for better matching\n",
    "salary_df[['City', 'State']] = salary_df['AREA_TITLE'].str.split(\",\", expand=True)\n",
    "\n",
    "# Remove any city after the initial City in some of the longer - ones\n",
    "salary_df['City'] = salary_df['City'].str.split('-').str[0].str.strip().str.title()\n",
    "salary_df['State'] = salary_df['State'].str.split('-').str[0].str.strip().str.upper()\n",
    "\n",
    "# Verify changes\n",
    "salary_df[['City', 'State']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be572289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City State\n",
       "1       New York    NY\n",
       "2    Los Angeles    CA\n",
       "3        Chicago    IL\n",
       "4         Dallas    TX\n",
       "5        Houston    TX\n",
       "6     Washington    DC\n",
       "7   Philadelphia    PA\n",
       "8          Miami    FL\n",
       "9        Atlanta    GA\n",
       "10        Boston    MA"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the State level rows from the housing_df dataset\n",
    "# Will only keep rows where the RegionName contains a , like \"Houston, TX\"\n",
    "# Will eliminate \"USA\", \"TX\" and other single state/country references\n",
    "housing_df = housing_df[housing_df['RegionName'].str.contains(\",\")]\n",
    "\n",
    "# Seperate the city, state into two seperate columns for better matching\n",
    "housing_df[['City', 'State']] = housing_df['RegionName'].str.split(\",\", expand=True)\n",
    "\n",
    "# Trim Whitespace from city and state columns\n",
    "housing_df['City'] = housing_df['City'].str.strip()\n",
    "housing_df['State'] = housing_df['State'].str.strip()\n",
    "\n",
    "# Verify changes\n",
    "housing_df[['City', 'State']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21311f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Honolulu</td>\n",
       "      <td>HI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Washington</td>\n",
       "      <td>DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City State\n",
       "0       New York    NY\n",
       "1       Honolulu    HI\n",
       "2  San Francisco    CA\n",
       "3        Seattle    WA\n",
       "4       San Jose    CA\n",
       "5     Washington    DC\n",
       "6         Boston    MA\n",
       "7    Los Angeles    CA\n",
       "8      San Diego    CA\n",
       "9          Miami    FL"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate the city, state into two seperate columns for better matching\n",
    "col_df[['City', 'State']] = col_df['City'].str.split(\",\", expand=True)\n",
    "\n",
    "# Trim Whitespace from city and state columns\n",
    "col_df['City'] = col_df['City'].str.strip()\n",
    "col_df['State'] = col_df['State'].str.strip()\n",
    "\n",
    "# Verify changes\n",
    "col_df[['City', 'State']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c642db",
   "metadata": {},
   "source": [
    "#### Merge the datasets into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd102388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA_TITLE</th>\n",
       "      <th>AREA_TYPE</th>\n",
       "      <th>PRIM_STATE</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NAICS_TITLE</th>\n",
       "      <th>I_GROUP</th>\n",
       "      <th>OWN_CODE</th>\n",
       "      <th>OCC_CODE</th>\n",
       "      <th>OCC_TITLE</th>\n",
       "      <th>...</th>\n",
       "      <th>9/30/2024</th>\n",
       "      <th>10/31/2024</th>\n",
       "      <th>11/30/2024</th>\n",
       "      <th>12/31/2024</th>\n",
       "      <th>1/31/2025</th>\n",
       "      <th>2/28/2025</th>\n",
       "      <th>3/31/2025</th>\n",
       "      <th>4/30/2025</th>\n",
       "      <th>5/31/2025</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>225237.5166</td>\n",
       "      <td>226581.6432</td>\n",
       "      <td>228173.2308</td>\n",
       "      <td>229368.0969</td>\n",
       "      <td>229336.9850</td>\n",
       "      <td>229195.4095</td>\n",
       "      <td>228894.9885</td>\n",
       "      <td>229352.6821</td>\n",
       "      <td>230157.0799</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>331359.7536</td>\n",
       "      <td>331825.2218</td>\n",
       "      <td>331632.6807</td>\n",
       "      <td>330622.7235</td>\n",
       "      <td>329226.6443</td>\n",
       "      <td>328415.2677</td>\n",
       "      <td>327703.3037</td>\n",
       "      <td>327341.4136</td>\n",
       "      <td>326610.5576</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10180.0</td>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cross-industry</td>\n",
       "      <td>cross-industry</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>15-2051</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>...</td>\n",
       "      <td>199842.9179</td>\n",
       "      <td>199634.2734</td>\n",
       "      <td>199439.6882</td>\n",
       "      <td>199545.9002</td>\n",
       "      <td>199890.3326</td>\n",
       "      <td>200418.3571</td>\n",
       "      <td>200560.5434</td>\n",
       "      <td>200357.8324</td>\n",
       "      <td>199927.0700</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10180.0</td>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cross-industry</td>\n",
       "      <td>cross-industry</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>29-1141</td>\n",
       "      <td>Registered Nurses</td>\n",
       "      <td>...</td>\n",
       "      <td>199842.9179</td>\n",
       "      <td>199634.2734</td>\n",
       "      <td>199439.6882</td>\n",
       "      <td>199545.9002</td>\n",
       "      <td>199890.3326</td>\n",
       "      <td>200418.3571</td>\n",
       "      <td>200560.5434</td>\n",
       "      <td>200357.8324</td>\n",
       "      <td>199927.0700</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>180876.6936</td>\n",
       "      <td>180471.5058</td>\n",
       "      <td>180541.2293</td>\n",
       "      <td>181386.8182</td>\n",
       "      <td>182609.4158</td>\n",
       "      <td>183337.5230</td>\n",
       "      <td>182884.6716</td>\n",
       "      <td>181262.8455</td>\n",
       "      <td>179577.4986</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>234550.8116</td>\n",
       "      <td>234190.4951</td>\n",
       "      <td>234223.4330</td>\n",
       "      <td>235002.8835</td>\n",
       "      <td>235660.1581</td>\n",
       "      <td>236096.3907</td>\n",
       "      <td>235658.3669</td>\n",
       "      <td>235363.2475</td>\n",
       "      <td>235660.6345</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>225302.6420</td>\n",
       "      <td>225766.0575</td>\n",
       "      <td>226372.1861</td>\n",
       "      <td>227555.0443</td>\n",
       "      <td>228911.3657</td>\n",
       "      <td>230204.7700</td>\n",
       "      <td>230915.8011</td>\n",
       "      <td>231337.2272</td>\n",
       "      <td>231601.3611</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>221119.3008</td>\n",
       "      <td>223553.8979</td>\n",
       "      <td>225583.0658</td>\n",
       "      <td>227825.5961</td>\n",
       "      <td>229366.2396</td>\n",
       "      <td>230899.0264</td>\n",
       "      <td>232116.3956</td>\n",
       "      <td>233353.6348</td>\n",
       "      <td>234137.3977</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>164814.5451</td>\n",
       "      <td>164414.2211</td>\n",
       "      <td>163829.2152</td>\n",
       "      <td>163850.1115</td>\n",
       "      <td>163969.3964</td>\n",
       "      <td>164174.5574</td>\n",
       "      <td>163855.4499</td>\n",
       "      <td>163080.5198</td>\n",
       "      <td>162098.2920</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>345645.9663</td>\n",
       "      <td>346679.8273</td>\n",
       "      <td>347446.9738</td>\n",
       "      <td>348533.3157</td>\n",
       "      <td>349414.1614</td>\n",
       "      <td>350478.6723</td>\n",
       "      <td>350971.9615</td>\n",
       "      <td>351749.9308</td>\n",
       "      <td>352790.9331</td>\n",
       "      <td>right_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AREA   AREA_TITLE  AREA_TYPE PRIM_STATE  NAICS     NAICS_TITLE  \\\n",
       "0      NaN          NaN        NaN        NaN    NaN             NaN   \n",
       "1      NaN          NaN        NaN        NaN    NaN             NaN   \n",
       "2  10180.0  Abilene, TX        4.0         TX    0.0  Cross-industry   \n",
       "3  10180.0  Abilene, TX        4.0         TX    0.0  Cross-industry   \n",
       "4      NaN          NaN        NaN        NaN    NaN             NaN   \n",
       "5      NaN          NaN        NaN        NaN    NaN             NaN   \n",
       "6      NaN          NaN        NaN        NaN    NaN             NaN   \n",
       "7      NaN          NaN        NaN        NaN    NaN             NaN   \n",
       "8      NaN          NaN        NaN        NaN    NaN             NaN   \n",
       "9      NaN          NaN        NaN        NaN    NaN             NaN   \n",
       "\n",
       "          I_GROUP  OWN_CODE OCC_CODE          OCC_TITLE  ...    9/30/2024  \\\n",
       "0             NaN       NaN      NaN                NaN  ...  225237.5166   \n",
       "1             NaN       NaN      NaN                NaN  ...  331359.7536   \n",
       "2  cross-industry    1235.0  15-2051    Data Scientists  ...  199842.9179   \n",
       "3  cross-industry    1235.0  29-1141  Registered Nurses  ...  199842.9179   \n",
       "4             NaN       NaN      NaN                NaN  ...  180876.6936   \n",
       "5             NaN       NaN      NaN                NaN  ...  234550.8116   \n",
       "6             NaN       NaN      NaN                NaN  ...  225302.6420   \n",
       "7             NaN       NaN      NaN                NaN  ...  221119.3008   \n",
       "8             NaN       NaN      NaN                NaN  ...  164814.5451   \n",
       "9             NaN       NaN      NaN                NaN  ...  345645.9663   \n",
       "\n",
       "    10/31/2024   11/30/2024   12/31/2024    1/31/2025    2/28/2025  \\\n",
       "0  226581.6432  228173.2308  229368.0969  229336.9850  229195.4095   \n",
       "1  331825.2218  331632.6807  330622.7235  329226.6443  328415.2677   \n",
       "2  199634.2734  199439.6882  199545.9002  199890.3326  200418.3571   \n",
       "3  199634.2734  199439.6882  199545.9002  199890.3326  200418.3571   \n",
       "4  180471.5058  180541.2293  181386.8182  182609.4158  183337.5230   \n",
       "5  234190.4951  234223.4330  235002.8835  235660.1581  236096.3907   \n",
       "6  225766.0575  226372.1861  227555.0443  228911.3657  230204.7700   \n",
       "7  223553.8979  225583.0658  227825.5961  229366.2396  230899.0264   \n",
       "8  164414.2211  163829.2152  163850.1115  163969.3964  164174.5574   \n",
       "9  346679.8273  347446.9738  348533.3157  349414.1614  350478.6723   \n",
       "\n",
       "     3/31/2025    4/30/2025    5/31/2025      _merge  \n",
       "0  228894.9885  229352.6821  230157.0799  right_only  \n",
       "1  327703.3037  327341.4136  326610.5576  right_only  \n",
       "2  200560.5434  200357.8324  199927.0700        both  \n",
       "3  200560.5434  200357.8324  199927.0700        both  \n",
       "4  182884.6716  181262.8455  179577.4986  right_only  \n",
       "5  235658.3669  235363.2475  235660.6345  right_only  \n",
       "6  230915.8011  231337.2272  231601.3611  right_only  \n",
       "7  232116.3956  233353.6348  234137.3977  right_only  \n",
       "8  163855.4499  163080.5198  162098.2920  right_only  \n",
       "9  350971.9615  351749.9308  352790.9331  right_only  \n",
       "\n",
       "[10 rows x 345 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge salary_df and housing_df into one dataframe\n",
    "salary_housing_df = pd.merge(salary_df, housing_df, on=['City', 'State'], how='outer', indicator=True)\n",
    "\n",
    "# Verify the merge worked\n",
    "salary_housing_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01b68afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows that exist in salary/housing but not in COL data\n",
    "unmatched_left = salary_housing_df[salary_housing_df['_merge'] == 'left_only'][['City', 'State']]\n",
    "\n",
    "# Rows that exist in COL but not in salary/housing\n",
    "unmatched_right = salary_housing_df[salary_housing_df['_merge'] == 'right_only'][['City', 'State']]\n",
    "\n",
    "# Optional: Reset index for viewing\n",
    "unmatched_left = unmatched_left.reset_index(drop=True)\n",
    "unmatched_right = unmatched_right.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7e321f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA_TITLE</th>\n",
       "      <th>AREA_TYPE</th>\n",
       "      <th>PRIM_STATE</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>NAICS_TITLE</th>\n",
       "      <th>I_GROUP</th>\n",
       "      <th>OWN_CODE</th>\n",
       "      <th>OCC_CODE</th>\n",
       "      <th>OCC_TITLE</th>\n",
       "      <th>...</th>\n",
       "      <th>4/30/2025</th>\n",
       "      <th>5/31/2025</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Cost of Living Index</th>\n",
       "      <th>Rent Index</th>\n",
       "      <th>Cost of Living Plus Rent Index</th>\n",
       "      <th>Groceries Index</th>\n",
       "      <th>Restaurant Price Index</th>\n",
       "      <th>Local Purchasing Power Index</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>347329.6436</td>\n",
       "      <td>347309.5393</td>\n",
       "      <td>48</td>\n",
       "      <td>58.9</td>\n",
       "      <td>31.3</td>\n",
       "      <td>46.8</td>\n",
       "      <td>67.5</td>\n",
       "      <td>64.1</td>\n",
       "      <td>165.8</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>390647.7478</td>\n",
       "      <td>389096.7596</td>\n",
       "      <td>18</td>\n",
       "      <td>69.2</td>\n",
       "      <td>42.5</td>\n",
       "      <td>57.5</td>\n",
       "      <td>79.9</td>\n",
       "      <td>70.6</td>\n",
       "      <td>170.2</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12420.0</td>\n",
       "      <td>Austin-Round Rock-San Marcos, TX</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cross-industry</td>\n",
       "      <td>cross-industry</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>15-2051</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>...</td>\n",
       "      <td>455311.8544</td>\n",
       "      <td>451858.3309</td>\n",
       "      <td>41</td>\n",
       "      <td>61.7</td>\n",
       "      <td>49.5</td>\n",
       "      <td>56.4</td>\n",
       "      <td>65.4</td>\n",
       "      <td>66.3</td>\n",
       "      <td>166.5</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12420.0</td>\n",
       "      <td>Austin-Round Rock-San Marcos, TX</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cross-industry</td>\n",
       "      <td>cross-industry</td>\n",
       "      <td>1235.0</td>\n",
       "      <td>29-1141</td>\n",
       "      <td>Registered Nurses</td>\n",
       "      <td>...</td>\n",
       "      <td>455311.8544</td>\n",
       "      <td>451858.3309</td>\n",
       "      <td>41</td>\n",
       "      <td>61.7</td>\n",
       "      <td>49.5</td>\n",
       "      <td>56.4</td>\n",
       "      <td>65.4</td>\n",
       "      <td>66.3</td>\n",
       "      <td>166.5</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>401962.2034</td>\n",
       "      <td>402126.9946</td>\n",
       "      <td>25</td>\n",
       "      <td>67.0</td>\n",
       "      <td>42.9</td>\n",
       "      <td>56.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>66.2</td>\n",
       "      <td>139.5</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>734297.7434</td>\n",
       "      <td>733270.3837</td>\n",
       "      <td>7</td>\n",
       "      <td>82.5</td>\n",
       "      <td>79.1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>87.3</td>\n",
       "      <td>145.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>391776.1566</td>\n",
       "      <td>390896.0049</td>\n",
       "      <td>27</td>\n",
       "      <td>66.6</td>\n",
       "      <td>46.7</td>\n",
       "      <td>57.9</td>\n",
       "      <td>77.3</td>\n",
       "      <td>63.9</td>\n",
       "      <td>145.7</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>341395.6137</td>\n",
       "      <td>341694.7701</td>\n",
       "      <td>15</td>\n",
       "      <td>71.5</td>\n",
       "      <td>55.8</td>\n",
       "      <td>64.6</td>\n",
       "      <td>79.2</td>\n",
       "      <td>75.8</td>\n",
       "      <td>157.3</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>300925.4526</td>\n",
       "      <td>301042.0854</td>\n",
       "      <td>49</td>\n",
       "      <td>54.8</td>\n",
       "      <td>36.2</td>\n",
       "      <td>46.7</td>\n",
       "      <td>60.6</td>\n",
       "      <td>53.4</td>\n",
       "      <td>170.2</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>243108.3076</td>\n",
       "      <td>243743.2934</td>\n",
       "      <td>44</td>\n",
       "      <td>61.2</td>\n",
       "      <td>33.7</td>\n",
       "      <td>49.2</td>\n",
       "      <td>69.3</td>\n",
       "      <td>56.4</td>\n",
       "      <td>134.7</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AREA                        AREA_TITLE  AREA_TYPE PRIM_STATE  NAICS  \\\n",
       "0      NaN                               NaN        NaN        NaN    NaN   \n",
       "1      NaN                               NaN        NaN        NaN    NaN   \n",
       "2  12420.0  Austin-Round Rock-San Marcos, TX        4.0         TX    0.0   \n",
       "3  12420.0  Austin-Round Rock-San Marcos, TX        4.0         TX    0.0   \n",
       "4      NaN                               NaN        NaN        NaN    NaN   \n",
       "5      NaN                               NaN        NaN        NaN    NaN   \n",
       "6      NaN                               NaN        NaN        NaN    NaN   \n",
       "7      NaN                               NaN        NaN        NaN    NaN   \n",
       "8      NaN                               NaN        NaN        NaN    NaN   \n",
       "9      NaN                               NaN        NaN        NaN    NaN   \n",
       "\n",
       "      NAICS_TITLE         I_GROUP  OWN_CODE OCC_CODE          OCC_TITLE  ...  \\\n",
       "0             NaN             NaN       NaN      NaN                NaN  ...   \n",
       "1             NaN             NaN       NaN      NaN                NaN  ...   \n",
       "2  Cross-industry  cross-industry    1235.0  15-2051    Data Scientists  ...   \n",
       "3  Cross-industry  cross-industry    1235.0  29-1141  Registered Nurses  ...   \n",
       "4             NaN             NaN       NaN      NaN                NaN  ...   \n",
       "5             NaN             NaN       NaN      NaN                NaN  ...   \n",
       "6             NaN             NaN       NaN      NaN                NaN  ...   \n",
       "7             NaN             NaN       NaN      NaN                NaN  ...   \n",
       "8             NaN             NaN       NaN      NaN                NaN  ...   \n",
       "9             NaN             NaN       NaN      NaN                NaN  ...   \n",
       "\n",
       "     4/30/2025    5/31/2025  Rank  Cost of Living Index  Rent Index  \\\n",
       "0  347329.6436  347309.5393    48                  58.9        31.3   \n",
       "1  390647.7478  389096.7596    18                  69.2        42.5   \n",
       "2  455311.8544  451858.3309    41                  61.7        49.5   \n",
       "3  455311.8544  451858.3309    41                  61.7        49.5   \n",
       "4  401962.2034  402126.9946    25                  67.0        42.9   \n",
       "5  734297.7434  733270.3837     7                  82.5        79.1   \n",
       "6  391776.1566  390896.0049    27                  66.6        46.7   \n",
       "7  341395.6137  341694.7701    15                  71.5        55.8   \n",
       "8  300925.4526  301042.0854    49                  54.8        36.2   \n",
       "9  243108.3076  243743.2934    44                  61.2        33.7   \n",
       "\n",
       "   Cost of Living Plus Rent Index  Groceries Index  Restaurant Price Index  \\\n",
       "0                            46.8             67.5                    64.1   \n",
       "1                            57.5             79.9                    70.6   \n",
       "2                            56.4             65.4                    66.3   \n",
       "3                            56.4             65.4                    66.3   \n",
       "4                            56.5             77.7                    66.2   \n",
       "5                            81.0             90.5                    87.3   \n",
       "6                            57.9             77.3                    63.9   \n",
       "7                            64.6             79.2                    75.8   \n",
       "8                            46.7             60.6                    53.4   \n",
       "9                            49.2             69.3                    56.4   \n",
       "\n",
       "  Local Purchasing Power Index  _merge  \n",
       "0                        165.8    both  \n",
       "1                        170.2    both  \n",
       "2                        166.5    both  \n",
       "3                        166.5    both  \n",
       "4                        139.5    both  \n",
       "5                        145.0    both  \n",
       "6                        145.7    both  \n",
       "7                        157.3    both  \n",
       "8                        170.2    both  \n",
       "9                        134.7    both  \n",
       "\n",
       "[10 rows x 352 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the _merge column, so we can re add it with this merge\n",
    "salary_housing_df = salary_housing_df.drop(columns=['_merge'])\n",
    "\n",
    "# Merge the new salary_housing_df with col_df and save as a new dataframe\n",
    "full_df = pd.merge(salary_housing_df, col_df, on=['City', 'State'], how='inner', indicator=True)\n",
    "\n",
    "full_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256eb6ff",
   "metadata": {},
   "source": [
    "#### Clean up the full_df to eliminate empty rows and not important data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b714277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows without an OCC_TITLE.  This is to eliminate rows where we don't have salaries for certain cities\n",
    "# ~ is the NOT qualifier in pandas\n",
    "full_df_cleaned = full_df[~full_df['OCC_TITLE'].isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3184d882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>OCC_TITLE</th>\n",
       "      <th>Avg_Annual_Salary</th>\n",
       "      <th>Avg_Home_Value</th>\n",
       "      <th>COL_Index</th>\n",
       "      <th>Purchasing_Power_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>124780</td>\n",
       "      <td>451858.3309</td>\n",
       "      <td>61.7</td>\n",
       "      <td>166.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>Registered Nurses</td>\n",
       "      <td>93060</td>\n",
       "      <td>451858.3309</td>\n",
       "      <td>61.7</td>\n",
       "      <td>166.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>119130</td>\n",
       "      <td>377185.6705</td>\n",
       "      <td>67.8</td>\n",
       "      <td>162.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>Registered Nurses</td>\n",
       "      <td>96720</td>\n",
       "      <td>377185.6705</td>\n",
       "      <td>67.8</td>\n",
       "      <td>162.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>Data Scientists</td>\n",
       "      <td>111440</td>\n",
       "      <td>314262.4259</td>\n",
       "      <td>61.6</td>\n",
       "      <td>169.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City State          OCC_TITLE  Avg_Annual_Salary  Avg_Home_Value  \\\n",
       "2    Austin    TX    Data Scientists             124780     451858.3309   \n",
       "3    Austin    TX  Registered Nurses              93060     451858.3309   \n",
       "12   Dallas    TX    Data Scientists             119130     377185.6705   \n",
       "13   Dallas    TX  Registered Nurses              96720     377185.6705   \n",
       "16  Houston    TX    Data Scientists             111440     314262.4259   \n",
       "\n",
       "    COL_Index  Purchasing_Power_Index  \n",
       "2        61.7                   166.5  \n",
       "3        61.7                   166.5  \n",
       "12       67.8                   162.7  \n",
       "13       67.8                   162.7  \n",
       "16       61.6                   169.8  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the columns we need\n",
    "selected_columns = [\n",
    "    'City', 'State', 'OCC_TITLE', 'A_MEAN', '5/31/2025',\n",
    "    'Cost of Living Index', 'Local Purchasing Power Index'\n",
    "]\n",
    "\n",
    "# Create the final_df with the seleced columns\n",
    "final_df = full_df_cleaned[selected_columns].copy()\n",
    "\n",
    "# Rename the columns for readability\n",
    "final_df = final_df.rename(columns={\n",
    "    'A_MEAN': 'Avg_Annual_Salary',\n",
    "    '5/31/2025': 'Avg_Home_Value',\n",
    "    'Cost of Living Index': 'COL_Index',\n",
    "    'Local Purchasing Power Index': 'Purchasing_Power_Index'\n",
    "})\n",
    "\n",
    "# Clean up the Avg_Annual_Salary so it can be converted to numeric\n",
    "final_df['Avg_Annual_Salary'] = (\n",
    "    final_df['Avg_Annual_Salary']\n",
    "    .str.replace('$', '', regex=False)\n",
    "    .str.replace(',', '', regex=False)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Convert the annual salary into numeric (currently object)\n",
    "final_df['Avg_Annual_Salary'] = pd.to_numeric(final_df['Avg_Annual_Salary'], errors='coerce')\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc54b9e",
   "metadata": {},
   "source": [
    "#### Sepearte Databases for each career, as well as create a joint database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b41a5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two seperate dataframes based on the jobs\n",
    "data_job_df = final_df[final_df['OCC_TITLE'] == 'Data Scientists'].copy()\n",
    "rn_df = final_df[final_df['OCC_TITLE'] == 'Registered Nurses'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c052087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add affordibility metric to each dataframe\n",
    "data_job_df['Affordability'] = data_job_df['Avg_Annual_Salary'] / (data_job_df['Avg_Home_Value'] * data_job_df['COL_Index'])\n",
    "rn_df['Affordability'] = rn_df['Avg_Annual_Salary'] / (rn_df['Avg_Home_Value'] * rn_df['COL_Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02cfcdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two databases into one\n",
    "combined_df = pd.merge(\n",
    "    data_job_df, rn_df,\n",
    "    on=['City', 'State'],\n",
    "    how='inner',\n",
    "    suffixes=('_You', '_RN')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf16d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the combined values into the combined_df\n",
    "combined_df['Combined_Income'] = (\n",
    "    combined_df['Avg_Annual_Salary_You'] + combined_df['Avg_Annual_Salary_RN']\n",
    ")\n",
    "\n",
    "\n",
    "# Keep the current home value and COL index (Should be equal across both RN and YOU dataframes)\n",
    "combined_df['Home_Value'] = combined_df['Avg_Home_Value_You']\n",
    "combined_df['COL_Index'] = combined_df['COL_Index_You']\n",
    "\n",
    "# Calculate the true affordability with combined income\n",
    "combined_df['Combined_Affordability'] = (\n",
    "    combined_df['Combined_Income'] / (combined_df['Home_Value'] * combined_df['COL_Index'])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5be10153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non needed columns from the combined_df\n",
    "combined_df = combined_df.drop(columns = [\n",
    "    'Avg_Home_Value_RN',\n",
    "    'Avg_Home_Value_You',\n",
    "    'COL_Index_You',\n",
    "    'COL_Index_RN',\n",
    "    'Purchasing_Power_Index_You',\n",
    "    'Purchasing_Power_Index_RN'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a04940a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Combined_Income</th>\n",
       "      <th>Home_Value</th>\n",
       "      <th>COL_Index</th>\n",
       "      <th>Combined_Affordability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>202590</td>\n",
       "      <td>286497.2030</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.011985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>208170</td>\n",
       "      <td>314262.4259</td>\n",
       "      <td>61.6</td>\n",
       "      <td>0.010753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>215850</td>\n",
       "      <td>377185.6705</td>\n",
       "      <td>67.8</td>\n",
       "      <td>0.008440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>217840</td>\n",
       "      <td>451858.3309</td>\n",
       "      <td>61.7</td>\n",
       "      <td>0.007814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>212420</td>\n",
       "      <td>459668.1680</td>\n",
       "      <td>67.2</td>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          City State  Combined_Income   Home_Value  COL_Index  \\\n",
       "4  San Antonio    TX           202590  286497.2030       59.0   \n",
       "2      Houston    TX           208170  314262.4259       61.6   \n",
       "1       Dallas    TX           215850  377185.6705       67.8   \n",
       "0       Austin    TX           217840  451858.3309       61.7   \n",
       "3    Nashville    TN           212420  459668.1680       67.2   \n",
       "\n",
       "   Combined_Affordability  \n",
       "4                0.011985  \n",
       "2                0.010753  \n",
       "1                0.008440  \n",
       "0                0.007814  \n",
       "3                0.006877  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df[['City', 'State', 'Combined_Income', 'Home_Value', 'COL_Index', 'Combined_Affordability']].sort_values(by='Combined_Affordability', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b974817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined_df to csv\n",
    "combined_df.to_csv('../data/combined_affordability.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
